# -*- coding: utf-8 -*-
"""
search_and_ask_with_memory.py
ğŸ”¹ Ù†Ø³Ø®Ø© Ù…Ù† search_and_ask ØªØ­ÙØ¸ ÙƒÙ„ Ø³Ø¤Ø§Ù„ ÙˆØ¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
ğŸ”¹ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: conversation Ùˆ message
"""

import os
import sys
import math
import json
import psycopg2
import requests
from textwrap import shorten
from datetime import datetime

# ===================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ =====================
DB = dict(
    host="localhost",
    port=5432,
    user="postgres",
    password="13@04@1971",
    dbname="nebras_rag",
)

LM_STUDIO_BASE = "http://127.0.0.1:1234/v1"
CHAT_MODEL = "mistralai/mistral-7b-instruct-v0.3"
EMBED_MODEL = "text-embedding-intfloat-multilingual-e5-large-instruct"

TOP_K = 5
MIN_ACCEPT = 0.55
MAX_TOKENS = 512
TEMPERATURE = 0.2
TIMEOUT = 180


# ===================== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© =====================
def cosine(a, b):
    if not a or not b or len(a) != len(b):
        return 0.0
    dot = sum(x*y for x, y in zip(a, b))
    na = math.sqrt(sum(x*x for x in a))
    nb = math.sqrt(sum(y*y for y in b))
    return 0.0 if (na == 0 or nb == 0) else dot / (na * nb)


def embed(text):
    """ØªÙˆÙ„ÙŠØ¯ ØªØ¶Ù…ÙŠÙ† Ø¹Ø¨Ø± LM Studio"""
    r = requests.post(f"{LM_STUDIO_BASE}/embeddings",
                      json={"model": EMBED_MODEL, "input": text},
                      timeout=TIMEOUT)
    r.raise_for_status()
    return r.json()["data"][0]["embedding"]


def connect_db():
    return psycopg2.connect(**DB)


def fetch_chunks():
    conn = connect_db()
    cur = conn.cursor()
    cur.execute("""
        SELECT id, book_id, book_name, content, embedding_vector
        FROM chunk
        ORDER BY id ASC
    """)
    rows = cur.fetchall()
    cur.close(); conn.close()
    return [dict(id=c, book_id=b, book_name=n, content=t, embedding=v)
            for c,b,n,t,v in rows]


def short_extract(text, max_words=20):
    words = text.split()
    return text if len(words) <= max_words else " ".join(words[:max_words]) + "..."


def verify_quote_in_chunk(quote, chunk_text):
    q = quote.strip().strip('"').rstrip("â€¦").rstrip("...")
    return q in chunk_text


def build_prompt(query, ranked):
    lines = []
    for i, r in enumerate(ranked, 1):
        excerpt = short_extract(r["content"], 20)
        lines.append(f"[Ù…Ø±Ø¬Ø¹ {i}] ÙƒØªØ§Ø¨: {r['book_name']}\n"
                     f'Ù…Ù‚ØªØ·Ù: "{excerpt}"\n'
                     f"Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {r['score']*100:.1f}%\n")
    sources = "\n".join(lines) if lines else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ØµØ§Ø¯Ø± ÙƒØ§ÙÙŠØ©."

    instruction = (
        "Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø¬Ø§Ø¨Ø© Ù…ÙˆØ¬Ø²Ø© ÙˆÙ…ØªÙ…Ø§Ø³ÙƒØ© ØªÙˆØ¶Ù‘Ø­ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø±ØŒ "
        "Ù…Ø¹ ØªØ¶Ù…ÙŠÙ† Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ø­Ø±ÙÙŠØ© Ù‚ØµÙŠØ±Ø© (â‰¤20 ÙƒÙ„Ù…Ø©) Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ "
        "Ù…Ø«Ù„ (Ù…Ø±Ø¬Ø¹ 1)ØŒ Ø«Ù… Ø£Ø®ØªÙ… Ø¨Ù‚Ø³Ù… Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©."
    )
    prompt = f"{instruction}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {query}\n\nØ§Ù„Ù…ØµØ§Ø¯Ø±:\n{sources}\n\n"
    return prompt.replace("{", "(").replace("}", ")")


def chat_with_completions(prompt):
    payload = {
        "model": CHAT_MODEL,
        "prompt": prompt,
        "max_tokens": MAX_TOKENS,
        "temperature": TEMPERATURE,
    }
    r = requests.post(f"{LM_STUDIO_BASE}/completions", json=payload, timeout=TIMEOUT)
    r.raise_for_status()
    data = r.json()
    return data["choices"][0].get("text", "").strip()


# ===================== Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª =====================
def ensure_conversation():
    conn = connect_db()
    cur = conn.cursor()
    cur.execute("SELECT id FROM conversation ORDER BY id DESC LIMIT 1;")
    row = cur.fetchone()
    if row:
        cid = row[0]
    else:
        cur.execute("INSERT INTO conversation (title, message_count) VALUES (%s, %s) RETURNING id;",
                    ("Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", 0))
        cid = cur.fetchone()[0]
        conn.commit()
    cur.close(); conn.close()
    return cid


def save_message(conversation_id, role, content, refs=None):
    conn = connect_db()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO message (conversation_id, role, content, references_json)
        VALUES (%s, %s, %s, %s)
    """, (conversation_id, role, content, json.dumps(refs) if refs else None))
    conn.commit()
    cur.close(); conn.close()


# ===================== Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====================
def ask(query):
    print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query}\n")
    print(f"ğŸ§© Chat Model: {CHAT_MODEL}")
    print(f"ğŸ§© Embed Model: {EMBED_MODEL}\n")

    query += " Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø§Ù„ØªØ­ÙˆÙ„ Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„ØªØ¹Ù„Ù… Ø¹Ù† Ø¨Ø¹Ø¯ ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„ØªØ¹Ù„ÙŠÙ… ØªØ·ÙˆÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙÙŠ Ø§Ù„ÙˆØ·Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ"
    q_vec = embed(query)
    chunks = fetch_chunks()

    scored = []
    for c in chunks:
        s = cosine(q_vec, c["embedding"])
        if s >= MIN_ACCEPT:
            scored.append({**c, "score": s})
    ranked = sorted(scored, key=lambda x: x["score"], reverse=True)[:TOP_K]

    if not ranked:
        print("âš ï¸ Ù„Ù… ØªÙØ¹Ø«Ø± Ù…Ù‚Ø§Ø·Ø¹ ÙƒØ§ÙÙŠØ© â‰¥ 55%.\n")
    else:
        print("ğŸ·ï¸ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹:")
        for i, r in enumerate(ranked, 1):
            print(f"- (Ù…Ø±Ø¬Ø¹ {i}) {r['book_name']} â€” ØªØ´Ø§Ø¨Ù‡: {r['score']*100:.1f}%")
            print("  Ù…Ù‚ØªØ·Ù:", shorten(r["content"], width=120, placeholder="â€¦"))
        print()

    prompt = build_prompt(query, ranked)
    answer = chat_with_completions(prompt)

    print("\nğŸ§  Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:\n", answer, "\n")

    print("ğŸ“– Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ (ØªØ­Ù‚Ù‚ Ø­Ø±ÙÙŠ):")
    refs = []
    for i, r in enumerate(ranked, 1):
        excerpt = short_extract(r["content"], 20)
        verified = verify_quote_in_chunk(excerpt, r["content"])
        refs.append({
            "book_name": r["book_name"],
            "similarity": round(r["score"]*100, 2),
            "excerpt": excerpt,
            "verified": verified
        })
        print(f"(Ù…Ø±Ø¬Ø¹ {i}) {r['book_name']} â€” ØªØ´Ø§Ø¨Ù‡: {r['score']*100:.1f}% â€” Ù…ØªØ­Ù‚Ù‚: {'âœ“' if verified else 'âœ—'}")
        print(f'Ù…Ù‚ØªØ·Ù: "{excerpt}"\n')

    # ğŸ’¾ Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    conv_id = ensure_conversation()
    save_message(conv_id, "user", query)
    save_message(conv_id, "assistant", answer, refs)
    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ conversation_id = {conv_id}\n")


# ===================== ØªÙ†ÙÙŠØ° Ù…Ø¨Ø§Ø´Ø± =====================
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Ø§Ø³ØªØ®Ø¯Ù…:\n  python search_and_ask_with_memory.py \"Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§\"")
        sys.exit(0)
    query = " ".join(sys.argv[1:])
    ask(query)
